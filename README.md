<!-- Note: the heading "neurosift-blog" gets included in the rendered view, so it is not necessary to include it in the markdown file. -->

[Rendered view](https://magland.github.io/neurosift-blog)

Links
* [Live site](https://neurosift.app)
* [Neurosift source code](https://github.com/flatironinstitute/neurosift)
* [Source for this document](https://github.com/magland/neurosift-blog)
* [Issues and feature requests](https://github.com/flatironinstitute/neurosift/issues)
* [Discussion](https://github.com/flatironinstitute/neurosift/discussions)

## Preview TwoPhotonSeries as Videos

2024-10-18

Neurosift now lets you preview TwoPhotonSeries data as videos, making it easier to assess data quality, detect motion artifacts, corruption, or simply explore the dataset. Since TwoPhotonSeries arrays in NWB files are often large and not optimized for streaming, loading can be slow. However, with the new Dendro-enabled view, you can quickly preview up to a minute of video to get an overview.

**How it works:**

When you open a TwoPhotonSeries object, you'll see a "Movie" tab where you can watch the video preview. If the Dendro job has already run, the video loads immediately. Otherwise, you can submit a new job, provided you have the necessary API key. The default preview duration is one minute, but you can adjust it for longer previews, though this will take more time to process.

<a href="https://neurosift.app/?p=/nwb&url=https://api.dandiarchive.org/api/assets/89256db6-8926-451f-b51f-8a7ae7c3c1f8/download/&dandisetId=000871&dandisetVersion=draft&tab=neurodata-item:/acquisition/raw_suite2p_motion_corrected|TwoPhotonSeries">Here’s an example from Dandiset 000871</a> (click the Movie tab).

![image](https://github.com/user-attachments/assets/5a6bca26-c8f6-430e-83d0-ddcc3d452239)


## AI generated Dandiset summaries and semantic search

2024-10-18

Neurosift has a feature where you can do a semantic search for relevant Dandisets by [pasting in a scientific abstract](https://neurosift.app/?p=/dandi-query) (click on "Search by abstract"). This is powered by a database of embeddings of Dandiset summaries that were automatically generated [here](https://github.com/magland/ai_generated_dandiset_summaries). These summaries were generated by an LLM using prompts created based on the content of the NWB files in the Dandiset and metadata for the Dandiset. You can check out the repo to see all the generated prompts and summaries for many of the public datasets. Right now this is just a snapshot in time, so unfortunately the search results do not include the most recent Dandisets.

![image](https://github.com/user-attachments/assets/bc78fde3-dbc4-410d-909b-8c465e329930)



## Multiscale Spike Density and Rastermap Integration

2024-10-17

Today, I came across a new paper in Nature Neuroscience that presents an exciting technique, which I decided to incorporate into Neurosift/Dendro (thanks Ben). [Rastermap](https://www.nature.com/articles/s41593-024-01783-4) is a method for visualizing large-scale neural recordings by sorting neurons based on their activity patterns. To build this into Neurosift, I added two new Dendro-enabled features.

**Multiscale Spike Density Plot**. The first new Dendro processor I implemented is a multiscale spike density plot. This plot downscales the spike train data (in a NWB units table) at multiple temporal resolutions, allowing users to zoom all the way out and still have the interface be responsive. By preparing the multiscale spike density array via a Dendro job, Neurosift now handles large spike train datasets much more efficiently. [Here's the source code](https://github.com/magland/dendro/blob/main/apps/hello_neurosift/MultiscaleSpikeDensity.py).

**Rastermap Integration**. The second feature is the integration of the Rastermap method. I added a new Dendro processor that computes the Rastermap ordering of the units, allowing for a more structured view of neural activity. Once the job is complete, Neurosift users can click a checkbox to display the spike density map using this Rastermap ordering, providing a refined visualization of unit activity based on their temporal relationships. [Here's the source code](https://github.com/magland/dendro/blob/main/apps/hello_rastermap/Rastermap.py).

I tried this out on a random Neuropixels example on Dandiset 000409 (IBL - Brain Wide Map). Go to <a href="https://neurosift.app/?p=/nwb&url=https://api.dandiarchive.org/api/assets/ab3998c2-3540-4bda-8b03-3f3795fa602d/download/&dandisetId=000409&dandisetVersion=draft&tab=view:SpikeDensityPlot|/units&tab-time=1270.6243529286096,1304.7577449409032,1281.0263022580411">this random example</a>, wait for the spike density map to load, and then click the "Use rastermap order" checkbox.

Here are screenshots without (top) and with (bottom) the rastermap order:

![image](https://github.com/user-attachments/assets/308f8b1f-680d-47d2-bc21-906ae751c0e4)

![image](https://github.com/user-attachments/assets/c0283d8e-4a22-41a0-bc66-fb2be579384e)

This can now be applied to any DANDI NWB file with a units table. You just need a Dendro API key with permission to run the new processors.


## Speedups in time series rendering

2024-10-16

Today, I made improvements to how time series data are rendered in Neurosift. Previously, users had to zoom in before they could see the data clearly. While this approach saved computational resources, it wasn't the most user-friendly experience. The new changes introduce an adaptive downsampling technique that samples minimum and maximum values based on the zoom level and the width of the window. This change allows the data to load at a wider range of zoom levels, improving the experience for users who found it annoying to have to zoom in initially.

The downsampling occurs entirely on the client side, so while the rendering performance has been improved, the same amount of data is downloaded to the browser as before. Optimizing the amount of data transferred is a more complex problem that involves preparing multiscale downsampled data ahead of time, which I’m actively working on. However, that will take more time to implement.

These enhancements should make the initial data viewing smoother and faster, especially for those working with
<a href="https://neurosift.app/?p=/nwb&url=https://api.dandiarchive.org/api/assets/c04f6b30-82bf-40e1-9210-34f0bcd8be24/download/&dandisetId=000409&dandisetVersion=draft&tab=neurodata-item:/acquisition/ElectricalSeriesAp|ElectricalSeries&tab-time=826.6977926933519,830.893730912819,826.502088310861">large time series datasets</a>.

![image](https://github.com/user-attachments/assets/2e1adb5a-10f3-4a9c-9949-6c502f038d1c)


## Conditional loading of documentation using AI function calls

2024-10-15

The Neurosift AI assistant can conditionally load documentation resources as needed based on the user's prompt. Here's the instructions that the assistant receives at this point.

```text
The following external resources are available using the "load_external_resource" tool - you should utilize these when appropriate.
...

* Create 2D tuning curves using Pynapple: https://github.com/magland/dandiset-notes/blob/main/dandisets/000582/000582.ipynb
* Load data objects from an NWB file using Pynapple: ./pynapple-docs.md
* Run spike sorting on data from this NWB file: ./spike-sorting-docs.md
* Iterate through the NWB files in a Dandiset: https://github.com/magland/dandiset-notes/blob/main/howto/dandi/iterate_through_nwb_files_in_dandiset.ipynb
```

The assistant/agent can call the `load_external_resource` tool to load the resource into the context. Typically [tool calls or function calls](https://platform.openai.com/docs/guides/function-calling) are used to retrieve records from a database or to do a calculation, so I wasn't sure if it would work for loading a document into the context. But based on preliminary testing with the gpt-4o model, it seems to work!

For example, on the [main Neurosift page]() you can open the chat and ask `"how to iterate through NWB files on Dandiset 000888?"`. You'll then see the assistant respond with `"load_external_resource https://github.com/magland/dandiset-notes/blob/main/howto/dandi/iterate_through_nwb_files_in_dandiset.ipynb"`, and then respond with the script based on what it learned from the content of the notebook.

From my preliminary experiments, other LLM models don't do as well with this type of thing.

## Pynapple 2D tuning curves

2024-10-14

Expanding on the previous post, I wanted to give the AI agent knowledge about creating 2D tuning curves using Pynapple (this was suggested by Ben). So I adapted [this tutorial notebook](https://pynapple.org/generated/examples/tutorial_pynapple_dandi/) into [this notebook](https://github.com/magland/dandiset-notes/blob/main/dandisets/000582/000582.ipynb) which is meant to be ingested by the AI agent. As described in the previous post, I then added an annotation to Dandiset 000582 on Neurosift to point to this notebook. Now when you open any NWB file from 000582 ([for example this one](https://neurosift.app/?p=/nwb&url=https://api.dandiarchive.org/api/assets/834ac48a-9bdf-4e79-a028-cbbf3136b01e/download/&dandisetId=000582&dandisetVersion=draft)), the AI agent will give you the option of including this as a resource inside the context, and you can ask something like: "Plot 2D tuning curves". There was an issue with the number of rows in the figure the first time I tried this, so I had to follow up with "You should take into consideration the number of units when you are generating the plot figure." The agent then adjusted the code accordingly and produced the following script:

```python
# Import necessary libraries
import pynwb
import lindi
import matplotlib.pyplot as plt
import pynapple as nap
import seaborn as sns

# Define the URL for the NWB file
url = 'https://lindi.neurosift.org/dandi/dandisets/000582/assets/834ac48a-9bdf-4e79-a028-cbbf3136b01e/nwb.lindi.json'

# Load the NWB file
f = lindi.LindiH5pyFile.from_lindi_file(url)
io = pynwb.NWBHDF5IO(file=f, mode='r')
nwbfile = io.read()

# Load the NWB file with Pynapple
nwbp = nap.NWBFile(nwbfile)

# Access the units and position data
units = nwbp["units"]  # TsGroup
position = nwbp["SpatialSeriesLED1"]  # 2D position data

# Compute 2D tuning curves
tc, binsxy = nap.compute_2d_tuning_curves(units, position, 20)

# Adjust plot size based on the number of units
num_units = len(units)
cols = 4
rows = (num_units + cols - 1) // cols  # Calculate rows needed
plt.figure(figsize=(15, 4 * rows))

# Styles for plotting
custom_params = {"axes.spines.right": False, "axes.spines.top": False}
sns.set_theme(style="ticks", palette="colorblind", font_scale=1.5, rc=custom_params)

# Plot 2D tuning curves
for i, (unit_id, tc_data) in enumerate(tc.items()):
    plt.subplot(rows, cols, i + 1)
    plt.imshow(tc_data, origin="lower", aspect="auto")
    plt.title(f"Unit {unit_id}")
plt.tight_layout()
plt.show()

# Close the file
io.close()
```

And upon execution you get a figure like the [one on the Pynapple docs](https://pynapple.org/generated/examples/tutorial_pynapple_dandi/).

Of course there are other Dandisets that could benefit from this resource, and in the future it would be nice if we didn't need to manually attach the notebook annotation to each Dandiset. Instead we would want to include this as a general resource that the agent could access when needed.

## AI-Driven Exploration of NWB Files: A Hands-on Experience with Dandiset 001037

2024-10-11

The last post focused on the Neurosift AI assistant in the context of Dandisets and DANDI as a whole. Today I extended the functionality of Neurosift's AI assistant to provide a more hands-on experience for *individual NWB files* within a Dandiset, especially for generating Python code for exploration and analysis, leveraging metadata from both the NWB file, the surrounding Dandiset, and external resources.

**Experimenting with 001037**

I started by experimenting with [Dandiset 001037](https://dandiarchive.org/dandiset/001037/0.240816.1841), aiming to reproduce a figure from the associated paper, "[Causal evidence of a line attractor encoding an affective state](https://www.nature.com/articles/s41586-024-07915-x)". While the assistant could load and explore the structure of the NWB file via pynwb, I quickly realized that it would need to be guided through the process. This ultimately resulted in a [Jupyter notebook](https://github.com/magland/dandiset-notes/blob/main/dandisets/001037/001037.ipynb) that was able to reproduce Figure 1d in the paper. I uploaded it to GithHub.

Then I realized it would be great to provide this specific notebook as a resource for my future interactions with the assistant, as well as for others coming across the same dataset. I used the existing Neurosift’s annotations feature to attach the URL of the notebook to the Dandiset. Then I added functionality to the assistant to detect linked resources and offer to optionally include them in the chat context for each session (for me or others).

Now in my chat (after selecting the notebook resource) I can just write "produce figure 1d for this NWB file" and it writes the code for me in a tidy script. Of course, it's just reproducing what I did in the notebook. However the usefulness became apparent when I tried it with a different NWB file in the same Dandiset. Again, for the second file, I selected the notebook in the assistant's context and prompted it to "produce figure 1d for this NWB file." The assistant analyzed the structure of the new NWB file and adjusted the code accordingly. It tweaked necessary names and parameters and successfully generated code for producing the corresponding figure for the new file.

**Try it out**

1. Go to [Dandiset 001037](https://neurosift.app/?p=/dandiset&dandisetId=001037&dandisetVersion=0.240816.1841).
2. Open one of the NWB files.
3. Click the chat icon in the left panel and select the notebook resource.
4. Ask the assistant to "produce figure 1d for this NWB file."
5. Copy the generated code and run it in your Python environment.
6. Repeat the process with another NWB file in the same Dandiset.

![image](https://github.com/user-attachments/assets/ef1c1236-9573-4c5f-bb0e-eda042f43bde)

The figure for the first NWB file (from the paper):
![image](https://github.com/user-attachments/assets/e761d9ad-fc34-4261-a24c-00bc37b072ae)


The figure for the second NWB file (not in the actual paper):
![image](https://github.com/user-attachments/assets/2ef2898d-cc2c-457d-b197-4e4409f9bd10)

**Implications**: Of course the question is why does the second figure look weird? Could it be a problem with the AI-generated code? Or is something odd with the data? Or is there more context and information needed? These are valuable questions! And questions we never would have known to ask without this type of exploration. **The assistant is not a replacement for a human, but it can be a powerful tool for guiding exploration.**

**Next Steps**: Try this type of thing with other Dandisets.

## AI assistant developments

2024-10-10

There is now a chat assistant side panel on the main DANDI exploration page. You can ask about DANDI, Neurosift, or how to search for data. It also has the ability to do a lexical search on its own, so you can ask it for data on a specific topic and it will return relevant Dandisets.

A more interesting new assistant is on the Dandiset page. As an agent, it can autonomously retrieve the following information:
* Metadata about the Dandiset (description, contributors, number of files, etc)
* A list of the NWB files in the Dandiset
* Details about a specific NWB files (efficient loading via LINDI).

So for example you can ask it "What are the Neurodata types in this Dandiset?" and it will do the necessary research. For example, try it out for [Dandiset 000472](https://neurosift.app/?p=/dandiset&dandisetId=000472&dandisetVersion=draft). You can even follow up with questions about the neurodata objects, as shown in the screenshot.

![image](https://github.com/user-attachments/assets/9f65a2be-36aa-4441-8d83-61b07e35c2e8)

**Next steps**: The next step is to develop the assistant for the single NWB file view. It should be aware of the data objects, available visualizations, and available Dendro analyses. It should also be able to generate Python code for loading the data objects, and creating basic figures using matplotlib. Ultimately, with Dendro integration, it should be able semi-automatically create create and execute analysis pipelines.

**Future**: Ultimately, we would like to be able to ask the assistant high level questions, and have it do research across all public datasets on DANDI.

## LINDI, Neurosift and Dendro: INCF workshop

2024-09-26

Today I gave a virtual presentation at the INCF Neuroinformatics Assembly, held in Austin. For the talk, I focused on LINDI, but I prepared three documents covering LINDI, Neurosift, and Dendro.

[Leveraging LINDI for efficient and non-redundant NWB access on DANDI](./talks/lindi_INCF_assembly_sep_2024.md)

LINDI is a cloud-friendly format for representing NWB files in a way that separates metadata from large binary data to optimize streaming and reduce redundancy. This presentation covers the various LINDI file formats and highlights the performance improvements in streaming NWB files using precomputed LINDI files. The talk also touches on future integration of LINDI with DANDI and Neurosift.

[Exploring NWB Datasets on DANDI with Neurosift](./talks/neurosift_INCF_assembly_sep_2024.md)

Here I introduce Neurosift, a browser-based tool designed to explore NWB files stored in the DANDI Archive. Neurosift enables users to interactively visualize neurophysiology data by lazy-loading NWB files, offering efficient data streaming even for large files. It integrates seamlessly with DANDI, allowing users to open files directly from the archive and explore them using various visualization plugins. Neurosift leverages the LINDI format to pre-index Dandisets, speeding up metadata loading, and provides an intuitive interface for navigating neurophysiology data.


[Analyzing NWB Datasets on DANDI with Dendro](./talks/dendro_INCF_assembly_sep_2024.md)

Dendro is a framework designed to facilitate the collaborative analysis of NWB files stored on DANDI. Dendro runs containerized jobs on local or remote compute resources, integrating seamlessly with Neurosift and DANDI to provide a streamlined experience. This presentation showcases an example of computing autocorrelograms for neural units. Additionally, it demonstrated the setup and use of custom compute clients for distributed processing and presented early-stage developments in spike sorting and other advanced analyses.

## Exploring and Analyzing NWB Datasets on DANDI with Neurosift and Dendro: MIT workshop

2024-09-13

[In this workshop](./talks/neurosift_dendro_MIT_workshop_sep_2024.md) at the McGovern Institute for Brain Research (MIT), I walked participants through the process of exploring and analyzing NWB datasets on DANDI using Neurosift and Dendro.

## Neurosift: DANDI exploration and NWB visualization in the browser: JOSS paper

2024-05-27

Today we [published a paper](https://joss.theoj.org/papers/10.21105/joss.06590) in the Journal of Open Source Software (JOSS) describing Neurosift.

JOSS reviews are open and transparent. Feel free to check out the [review thread](https://github.com/openjournals/joss-reviews/issues/6590).

**Abstract:** Neurosift, a browser-based visualization tool, is designed for the interactive exploration of Neurodata Without Borders (NWB) files, whether stored locally, on remote servers, or within the Distributed Archives for Neurophysiology Data Integration (DANDI). NWB (Rübel et al., 2022; Teeters et al., 2015) is an open data standard for neurophysiology that enables the sharing, archiving, and analysis of various types of neurophysiology data. DANDI (Rübel et al., 2022) is a cloud-based platform that supports the storage, sharing, and analysis of neurophysiology data including NWB files. With Neurosift integration, users browsing DANDI can easily open any NWB file in the browser and explore its contents, including timeseries data, images, and more. Neurosift can also be used to browse the DANDI database or individual Dandisets. Overall, Neurosift simplifies the visualization and exploration of complex NWB file structures, making it a valuable tool for neuroscientists.

